= Test Mule Applications
ifndef::env-site,env-github[]
include::_attributes.adoc[]
endif::[]

Building a comprehensive suite of automated tests for a Mule Application enables you to detect any regression or incompatible change in your application during tests in a local environment.

MUnit is a Mule testing framework that lets you easily automate testing Mule applications, using both _unit_ and _integration_ tests. MUnit also provides a set of tools, such as a processor mocking framework that lets you test units of code in isolation.

See the xref:munit::index.adoc[MUnit] documentation for more details.

Profiling Mule runtime engine (Mule) can help you identify memory or performance-related issues in Mule applications or custom Mule extensions. To profile Mule, you need to load a Java Profiler into your on-premises Mule instance.

See xref:profiling-mule.adoc[Profiling Mule] for more instructions.

== Unit Tests

The concept of unit tests may vary according to the programming paradigm that you are working on, but it always points to the same core concept: _to validate the correctness of an individual unit of source code_.

In the context of unit testing, a unit of code is the smallest testable part of an application. What exactly constitutes the smallest testable part of an application depends on the application. When testing Mule applications, MuleSoft considers that the smallest testable part is a Mule flow or a sub-flow.

Test cases must be independent of each other and it is the developerâ€™s responsibility to ensure test inter-independency.
The code you test might interact with other units of code or components, always consider this possibility when designing unit tests. A good unit test ensures the isolation of the unit of code being tested, to avoid mistaking failure in other components for failure in the unit of code being tested.

To isolate the target unit of code, use tools such as the `mock-when` processor provided by MUnit.

See xref:munit::mock-before-after-foreach-cookbook.adoc[Mocking a Message Before and Inside a Foreach Processor] for a usage example of the `mock-when` processor.

== Integration Tests

Units of code collaborate between them to create an actual application. You test individual units of code with unit tests, and you test how units of code collaborate between them with integration tests.

The goal of an Integration test is _to validate that different units of code and modules work together as intended_.
Integration tests must aggregate units of code modules that have already been successfully unit-tested. For this reason, always run your integration tests after your unit tests.

Depending on the nature of your application, integration tests may require sandboxes, that is, environments for your application to connect to. When working with sandboxes, ensure that the state of the data in the sandbox is correct for the test to produce the intended result. Perform this verification before and after running the integration test.

== Writing Testable Code

The following guidelines help you create flows that are easier to test. Writing testable code implies creating a more configurable, extensible, and readable application.

* Modularize your code
+
Breaking down your code in different files helps with readability. Do this by grouping flows that work together to achieve a common goal, or group code according to specific functional criteria.
* Write short flows
+
Long flows are often hard to follow, harder to code, and harder to maintain. From the perspective of unit testing, long flows offer too many scenarios that can be triggered by a single point. Long flows might require you to perform very complex evaluations to validate a single scenario and are best avoided.
* Define execution environments
+
Parameterize your code using placeholders. Normal use cases for this include addresses of outbound endpoints, such as DB or HTTP. Using placeholders enables you to modify the actual address when running tests (either unit or integration), and make it easier to promote your code between environments (DEV/QA/UAT/PROD).

== Tips for Writing Tests

* Write your tests to be readable and maintainable.
* Name your test according to what you want to see when the test fails.
* Use descriptive names for the error thrown by the test upon failure. This helps you avoid receiving wrongly-written or ambiguous error messages when the test fails.
* Avoid long flows because they are harder to follow.
* Code your test so that the scenario being covered and the failure conditions are explicit.

== See Also

* xref:munit::munit-test-concept.adoc[MUnit Test Structure Fundamentals]
* xref:munit::munit-cookbook.adoc[MUnit Examples]
